# üìä Observability with Prometheus, Alertmanager, EFK & Jaeger

This project demonstrates how to implement **observability** in microservices by combining **metrics, logging, tracing, and alerting**.  
You‚Äôll learn how to instrument applications, visualize metrics, collect logs, set up alerts, and trace requests across services.

---
# The Process of create Costume Metric
- ``Instrument`` the Metric
- ``Set up Prometheus`` or your complete Monitoring
- ``Service Discovery`` It tells you the service that you want to Identify

These 3 Process is the Process of Create Costume Metric. you can additionally set up an alert with ``Gmail``.

## üéõÔ∏è What is Instrumentation?
Instrumentation refers to adding monitoring capabilities to applications, systems, or services.  
This involves embedding code or using tools to collect **metrics, logs, or traces** that provide insights into how the system is performing.

### üéØ Purpose of Instrumentation
- **Visibility** ‚Üí Gain insight into application & infrastructure state.  
- **Metrics Collection** ‚Üí Collect CPU usage, memory, request rates, error rates, etc.  
- **Troubleshooting** ‚Üí Diagnose failures faster with detailed insights.  

### ‚öôÔ∏è How It Works
- **Code-Level Instrumentation** ‚Üí Add code to expose metrics.  
  Example: in Node.js use [`prom-client`](https://github.com/siimon/prom-client) to create custom metrics.

---

## üìà Metrics in Prometheus

### üîÑ Counter
- Always increases.  
- Example: count HTTP requests, errors, or container restarts.  
- **Metric Example:** `kube_pod_container_status_restarts_total`

### üìè Gauge
- Goes up and down.  
- Example: memory usage, CPU usage, active users.  
- **Metric Example:** `container_memory_usage_bytes`

### üìä Histogram
- Measures observations in buckets (e.g., request durations).  
- Provides **count, sum, and bucket breakdowns**.  
- **Metric Example:** `apiserver_request_duration_seconds_bucket`

### üìù Summary
- Similar to histogram, but with **quantiles (percentiles)**.  
- Example: 95th percentile request duration.  
- **Metric Example:** `apiserver_request_duration_seconds_sum`

---

## üè† Architecture

![Project Architecture](images/architecture.gif)

### Components:
- **Service A & B (Node.js apps)** ‚Üí instrumented with `prom-client`.  
- **Prometheus** ‚Üí scrapes metrics from services.  
- **Alertmanager** ‚Üí sends alerts (via email/SMTP).  
- **EFK Stack** ‚Üí centralized logging (Elasticsearch, FluentBit, Kibana).  
- **Jaeger** ‚Üí distributed tracing for request flows.  
- **Kubernetes** ‚Üí orchestration and service discovery.  

---

## üéØ Project Objectives
- üõ†Ô∏è **Implement Custom Metrics in Node.js** with `prom-client`.  
- üö® **Set Up Alerts in Alertmanager** (e.g., pod restart > 2 times).  
- üìù **Centralized Logging with EFK**.  
- üì∏ **Distributed Tracing with Jaeger**.  

---

## 1Ô∏è‚É£ Write Custom Metrics

File: `day-4/application/service-a/index.js`

Metrics implemented:
- `http_requests_total` ‚Üí Counter  
- `http_request_duration_seconds` ‚Üí Histogram  
- `http_request_duration_summary_seconds` ‚Üí Summary  
- `node_gauge_example` ‚Üí Gauge  

### Routes
- `/` ‚Üí Running status  
- `/healthy` ‚Üí Health check  
- `/serverError` ‚Üí Simulate 500  
- `/notFound` ‚Üí Simulate 404  
- `/logs` ‚Üí Generate logs  
- `/crash` ‚Üí Simulate crash  
- `/example` ‚Üí Async gauge  
- `/metrics` ‚Üí Prometheus metrics  
- `/call-service-b` ‚Üí Call service B  

---

## 2Ô∏è‚É£ Dockerize & Push to Registry
```bash
cd day-4

# Service A
docker build -t <REPO>:<TAG> application/service-a/
# Service B
docker build -t <REPO>:<TAG> application/service-b/

```
3Ô∏è‚É£ Deploy to Kubernetes
```bash
kubectl create ns dev
kubectl apply -k kubernetes-manifest/
```

4Ô∏è‚É£ Test Endpoints
Get the LoadBalancer DNS and test:

```bash
Copy code
/
 /healthy
 /serverError
 /notFound
 /logs
 /example
 /metrics
 /call-service-b
Automated test script:
```
```bash
./test.sh <LOAD_BALANCER_DNS_NAME>
```
## 5Ô∏è‚É£ Configure Alertmanager
Files: day-4/alerts-alertmanager-servicemonitor-manifest
```
Steps:

1. Generate Gmail App Password (or AWS SES SMTP).

2. Put it in email-secret.yml.

3. Add your email in alertmanagerconfig.yml.

Alerts
HighCpuUsage ‚Üí Warning if CPU > 50% for 5m.

PodRestart ‚Üí Critical if pod restarts > 2 times.
```
Apply:

```bash
kubectl apply -k alerts-alertmanager-servicemonitor-manifest/
```
## 6Ô∏è‚É£ Centralized Logging with EFK
FluentBit (DaemonSet) Collects logs from pods.

Forwards to Elasticsearch.

Example config ``(fluentbit-configmap.yml)``:

```bash
Copy code
[OUTPUT]
    Name es
    Match *
    Host elasticsearch
    Port 9200
    Index kubernetes-logs
```
## Elasticsearch
Deploy with StatefulSet (elasticsearch.yml).

## Kibana
Deploy UI (kibana.yml) and access logs via browser.

## 7Ô∏è‚É£ Distributed Tracing with Jaeger
Install Jaeger in Kubernetes
```bash
kubectl create namespace observability
```
```bash
kubectl apply -f https://github.com/jaegertracing/jaeger-operator/releases/download/v1.49.0/jaeger-operator.yaml
```
## Instrument Node.js (Service A)
```bash
Copy code
const { NodeTracerProvider } = require('@opentelemetry/sdk-trace-node');
const { SimpleSpanProcessor } = require('@opentelemetry/sdk-trace-base');
const { JaegerExporter } = require('@opentelemetry/exporter-jaeger');

const provider = new NodeTracerProvider();
const exporter = new JaegerExporter({
  serviceName: 'service-a',
  endpoint: 'http://jaeger-collector:14268/api/traces',
});
```
provider.addSpanProcessor(new SimpleSpanProcessor(exporter));
provider.register();
## 8Ô∏è‚É£ Test Alerts
Crash the container more than 2 times:

```bash
Copy code
<LOAD_BALANCER_DNS>/crash
üëâ Expect email alert when restart count ‚â• 3.
```
‚úÖ Summary
You now have a complete observability pipeline:

- Metrics ‚Üí Prometheus & custom instrumentation.

- Logging ‚Üí EFK stack.

- Tracing ‚Üí Jaeger.

- Alerting ‚Üí Alertmanager.

- Deployment ‚Üí Kubernetes.

- This setup provides visibility, troubleshooting, and performance monitoring across microservices.